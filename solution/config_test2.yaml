# 全局参数
project_name: 'all'                                         # 项目名称，用于区分配置
dataset_path: 'dj_synth_challenge/input/pretrain_stage_2/test.jsonl'                       # 数据集目录或文件路径，包含权重(0.0-1.0)，默认权重为1.0。
                                                            # 接受的格式：'权重1(可选) 数据集1路径 权重2(可选) 数据集2路径'
export_path: 'dj_synth_challenge/output/test.jsonl'                # 处理结果数据集的路径。支持的后缀包括['jsonl', 'json', 'parquet']
export_shard_size: 0                                        # 导出数据集的分片大小（以字节为单位）。默认值为0，表示将整个数据集导出为一个文件。如果设置为正数，导出数据集将被分割为多个分片，每个分片的最大大小不超过export_shard_size
export_in_parallel: false                                   # 是否以并行方式导出结果数据集到单个文件，通常会节省时间。仅在export_shard_size为0时有效，默认进程数与参数np相同。**注意**：如果设置为True，有时由于IO阻塞，并行导出可能需要更多时间，尤其对于非常大的数据集。这种情况下，设置为False虽然耗时更长，但可能更合适。
np: 16                                                       # 处理数据集的子进程数
                                      # 样本文本字段的键名，例如 `text`, `instruction`, `output`, ...
                                                            # 注意：当前仅支持指定一个键名，对于需要多个键的情况，用户可以多次指定操作。设置多个键时，仅使用第一个键。

# for multimodal data processing
image_key: 'images'                                         # 存储样本图像路径列表的字段键名
image_special_token: '<__dj__image>'                        # 表示图像的特殊标记

eoc_special_token: ''                                       # 表示块结束的特殊标记
# eoc_special_token: '<EOC>'  # 设置为一个特殊标记



# process schedule: a list of several process operators with their arguments
process:
  # 过滤器操作

  - image_text_matching_filter: # 根据图像和文本之间的匹配分数过滤样本。
      hf_blip: Salesforce/blip-itm-base-coco                  # 使用的 Hugging Face blip 的名称 Salesforce/blip-itm-large-coco
      min_score: 0.85                                        # 过滤范围的最小匹配分数
      max_score: 1.0                                          # 过滤范围的最大匹配分数
      horizontal_flip: false                                  # 水平翻转图像（左右翻转）。
      vertical_flip: false                                    # 垂直翻转图像（上下翻转）。
      reduce_mode: avg                                        # 当一个文本对应多个图像时的简化模式，必须是 ['avg','max', 'min'] 之一。
      any_or_all: any                                         # 当任何/所有图像符合过滤条件时保留此样本
      mem_required: '1500MB'                                  # 此操作（Op）利用深度神经网络模型进行计算，消耗大量内存，因此系统可用内存可能限制可启动的进程数

  - image_text_similarity_filter: # 根据图像和文本之间的相似性过滤样本。
      hf_clip: openai/clip-vit-base-patch32                   # 用于计算帧图像和文本相似性的 clip 模型名称。它与语言相关。例如，对于中文数据集，
      #                                                                 ChineseCLIP 可能是更好的选择 。openai/clip-vit-large-patch14
      min_score: 0.282                                          # 保留样本的最小相似性。
      max_score: 1.0                                          # 保留样本的最大相似性。
      horizontal_flip: false                                  # 水平翻转图像（左右翻转）。
      vertical_flip: false                                    # 垂直翻转图像（上下翻转）。
      reduce_mode: avg                                        # 当一个文本对应多个视频时的简化模式，必须是 ['avg','max', 'min'] 之一。
      any_or_all: any                                         # 当任何/所有图像符合过滤条件时保留此样本
      mem_required: '1500MB'                                  # 此操作（Op）利用深度神经网络模型进行计算，消耗大量内存，因此系统可用内存可能限制可启动的进程数

